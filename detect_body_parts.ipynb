{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Body Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from models.config import get_default_configuration\n",
    "from tensorflow.keras.models import load_model\n",
    "from models.model import get_model\n",
    "from models.calculateDistance import calculateDistances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before to run this notebook run first dataset_framing notebook\n",
    "\n",
    "To see a more detailed execution of how body parts are detected, with graphical examples take a look to the openpose_example notebook\n",
    "\n",
    "What this notebook does:\n",
    "\n",
    "- takes in input an image from the framed_dataset_small folder\n",
    "- for each person in the image, detect body parts\n",
    "- for each frame, calculate distance between selected bodyparts -> for implementation models/calculateDistancce\n",
    "- save the result in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keras model load the weights file for OpenPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"models/weights.h5\"\n",
    "model = get_model(1.0, 224)\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has 101 features: \n",
    "\n",
    "- an Id for the frame: userful, because not all the proccessed frame are saved in the final dataframe: only   \n",
    "    frames with exactly two people will be considerated.\n",
    "- X Coordinate and Y Coordinate of each body part (17) of the first person Eg. XNose1, YNose1\n",
    "- X Coordinate and Y Coordinate of each body part (17) of the second person Eg. XNose2, YNose2\n",
    "- Distances between selected body parts\n",
    "- Boolean tag for Violence/NonViolence\n",
    "\n",
    "\n",
    "Following a list of all the distances considerated:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DistNeckHip1\n",
    "DistNeckHip2\n",
    "                   \n",
    "DistNoseLWrist1\n",
    "DistNoseRWrist1\n",
    "DistNoseLKnee1\n",
    "DistNoseRKnee1\n",
    "                   \n",
    "DistLHipLWrist1\n",
    "DistLHipRWrist1\n",
    "DistRHipLWrist1\n",
    "DistRHipRWrist1 \n",
    "DistLHipLKnee1\n",
    "DistLHipRKnee1\n",
    "DistRHipLKnee1\n",
    "DistRHipRKnee1\n",
    "                   \n",
    "\n",
    "DistNoseLWrist2\n",
    "DistNoseRWrist2\n",
    "DistNoseLKnee2\n",
    "DistNoseRKnee2\n",
    "                   \n",
    "DistLHipLWrist2\n",
    "DistLHipRWrist2\n",
    "DistRHipLWrist2\n",
    "DistRHipRWrist2 \n",
    "DistLHipLKnee2\n",
    "DistLHipRKnee2\n",
    "DistRHipLKnee2\n",
    "DistRHipRKnee2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'idFrame' : [],\n",
    "                   \"Xnose1\" : [],\"Ynose1\" : [],\"Xnose2\" : [],\"Ynose2\" : [], \n",
    "                   \"Xneck1\" : [],\"Yneck1\" : [],\"Xneck2\" : [],\"Yneck2\" : [], \n",
    "                   \"XRshoulder1\" : [], \"YRshoulder1\" : [], \"XRshoulder2\" : [],\"YRshoulder2\" : [],\n",
    "                   \"XRelbow1\" : [],\"YRelbow1\" : [],\"XRelbow2\" : [], \"YRelbow2\" : [],\n",
    "                   \"XRwrist1\" : [],\"YRwrist1\" : [],\"XRwrist2\" : [],\"YRwrist2\" : [],\n",
    "                   \"XLShoulder1\" : [],\"YLShoulder1\" : [],\"XLShoulder2\" : [],\"YLShoulder2\" : [],\n",
    "                   \"XLelbow1\" : [],\"YLelbow1\" : [],\"XLelbow2\" : [],\"YLelbow2\" : [],\n",
    "                   \"XLwrist1\" : [],\"YLwrist1\" : [],\"XLwrist2\" : [],\"YLwrist2\" : [],\n",
    "                   \"XRhip1\" : [],\"YRhip1\" : [],\"XRhip2\" : [],\"YRhip2\" : [],\n",
    "                   \"XRknee1\" : [],\"YRknee1\" : [],\"XRknee2\" : [],\"YRknee2\" : [],\n",
    "                   \"XRankle1\" : [], \"YRankle1\" : [], \"XRankle2\" : [], \"YRankle2\" : [],\n",
    "                   \"XLhip1\" : [], \"YLhip1\" : [], \"XLhip2\" : [], \"YLhip2\" : [], \n",
    "                   \"XLknee1\" : [], \"YLknee1\" : [],\"XLknee2\" : [],\"YLknee2\" : [],\n",
    "                   \"XLankle1\" : [],\"YLankle1\" : [],\"XLankle2\" : [],\"YLankle2\" : [],\n",
    "                   \"XReye1\" : [], \"YReye1\" : [],\"XReye2\" : [],\"YReye2\" : [],\n",
    "                   \"XLeye1\" : [],\"YLeye1\" : [],\"XLeye2\" : [],\"YLeye2\" : [],\n",
    "                   \"XRear1\" : [],\"YRear1\" : [],\"XRear2\" : [],\"YRear2\" : [],\n",
    "                   \"XLear1\" : [],\"YLear1\" : [],\"XLear2\" : [],\"YLear2\" : [],\n",
    "                   \"DistNeckHip1\" : [], \"DistNeckHip2\" : [], \n",
    "                   \"DistNoseLWrist1\" : [],\"DistNoseRWrist1\" : [],\"DistNoseLKnee1\" : [],\"DistNoseRKnee1\" : [],\n",
    "                   \"DistLHipLWrist1\" : [],\"DistLHipRWrist1\" : [],\"DistRHipLWrist1\" : [],\"DistRHipRWrist1\" : [],\n",
    "                   \"DistLHipLKnee1\" : [],\"DistLHipRKnee1\" : [],\"DistRHipLKnee1\" : [],\"DistRHipRKnee1\" : [],\n",
    "                   \"DistNoseLWrist2\" : [],\"DistNoseRWrist2\" : [],\"DistNoseLKnee2\" : [],\"DistNoseRKnee2\" : [],\n",
    "                   \"DistLHipLWrist2\" : [],\"DistLHipRWrist2\" : [],\"DistRHipLWrist2\" : [],\"DistRHipRWrist2\" : [],\n",
    "                   \"DistLHipLKnee2\" : [],\"DistLHipRKnee2\" : [],\"DistRHipLKnee2\" : [],\"DistRHipRKnee2\" : [],\n",
    "                   \"Violence\" : []})\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts = {\n",
    "    0 : \"nose\",\n",
    "    1 : \"neck\",\n",
    "    2 : \"Rshoulder\",\n",
    "    3 : \"Relbow\",\n",
    "    4 : \"Rwrist\",\n",
    "    5 : \"LShoulder\",\n",
    "    6 : \"Lelbow\",\n",
    "    7 : \"Lwrist\",\n",
    "    8 : \"Rhip\",\n",
    "    9 : \"Rknee\",\n",
    "    10 : \"Rankle\",\n",
    "    11 : \"Lhip\",\n",
    "    12 : \"Lknee\",\n",
    "    13 : \"Lankle\",\n",
    "    14 : \"Reye\",\n",
    "    15 : \"Leye\",\n",
    "    16 : \"Rear\",\n",
    "    17 : \"Lear\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numFrame in range(6934,12487): #Range for Non Violence folder MAKE SURE TO CHANGE THE IMAGE PATH\n",
    "#for numFrame in range(6934): #Range for Violence folder MAKE SURE TO CHANGE THE IMAGE PATH\n",
    "    path = \"dataset_framing/framed_dataset_small/nonviolence/img\"+str(numFrame)+\".jpg\" \n",
    "    frame= dict()\n",
    "    people = dict()\n",
    "    oriImg = cv2.imread(path)\n",
    "    input_img = oriImg[np.newaxis,...] \n",
    "    output_blobs = model.predict(input_img) #generate heatmaps and paf vectors\n",
    "    heatmap = output_blobs[3]\n",
    "    heatmap = heatmap[0]\n",
    "    paf = output_blobs[2] \n",
    "    paf = paf[0]\n",
    "    config = get_default_configuration()\n",
    "    all_peaks = []\n",
    "    peak_counter = 0\n",
    "    thre1 = 0.1\n",
    "    hashMap = dict() \n",
    "\n",
    "    for part_meta in config.body_parts.values():\n",
    "        map = heatmap[:, :, part_meta.heatmap_idx]    \n",
    "\n",
    "        map_left = np.zeros(map.shape)\n",
    "        map_left[1:,:] = map[:-1,:]\n",
    "        map_right = np.zeros(map.shape)\n",
    "        map_right[:-1,:] = map[1:,:]\n",
    "        map_up = np.zeros(map.shape)\n",
    "        map_up[:,1:] = map[:,:-1]\n",
    "        map_down = np.zeros(map.shape)\n",
    "        map_down[:,:-1] = map[:,1:]\n",
    "\n",
    "        peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > thre1))\n",
    "        peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0])) # note reverse\n",
    "        peaks_with_score = [x + (map[x[1],x[0]],) for x in peaks]\n",
    "        id = range(peak_counter, peak_counter + len(peaks))\n",
    "        peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
    "\n",
    "        for i in id:\n",
    "            hashMap[i]=part_meta.body_part.name \n",
    "\n",
    "        all_peaks.append(peaks_with_score_and_id)\n",
    "        peak_counter += len(peaks)\n",
    "    # find connection in the specified sequence, center 29 is in the position 15\n",
    "    limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "               [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "               [1,16], [16,18], [3,17], [6,18]]\n",
    "    # the middle joints heatmap correpondence\n",
    "    mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22], \\\n",
    "              [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], \\\n",
    "              [55,56], [37,38], [45,46]]\n",
    "    thre2 = 0.05\n",
    "\n",
    "    connection_all = []\n",
    "    special_k = []\n",
    "    mid_num = 10\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        score_mid = paf[:,:,[x-19 for x in mapIdx[k]]]\n",
    "        candA = all_peaks[limbSeq[k][0]-1]\n",
    "        candB = all_peaks[limbSeq[k][1]-1]\n",
    "        nA = len(candA)\n",
    "        nB = len(candB)\n",
    "        indexA, indexB = limbSeq[k]\n",
    "        if(nA != 0 and nB != 0):\n",
    "            connection_candidate = []\n",
    "            for i in range(nA):\n",
    "                for j in range(nB):\n",
    "                    vec = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                    norm = math.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
    "                    # failure case when 2 body parts overlaps\n",
    "                    if norm == 0:\n",
    "                        continue\n",
    "                    vec = np.divide(vec, norm)\n",
    "\n",
    "                    startend = list(zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), \\\n",
    "                                   np.linspace(candA[i][1], candB[j][1], num=mid_num)))\n",
    "\n",
    "                    vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] \\\n",
    "                                      for I in range(len(startend))])\n",
    "                    vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] \\\n",
    "                                      for I in range(len(startend))])\n",
    "\n",
    "                    score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                    score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*oriImg.shape[0]/norm-1, 0)\n",
    "                    criterion1 = len(np.nonzero(score_midpts > thre2)[0]) > 0.8 * len(score_midpts)\n",
    "                    criterion2 = score_with_dist_prior > 0\n",
    "                    if criterion1 and criterion2:\n",
    "                        connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
    "\n",
    "            connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "            connection = np.zeros((0,5))\n",
    "            for c in range(len(connection_candidate)):\n",
    "                i,j,s = connection_candidate[c][0:3]\n",
    "                if(i not in connection[:,3] and j not in connection[:,4]):\n",
    "                    connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
    "                    if(len(connection) >= min(nA, nB)):\n",
    "                        break\n",
    "\n",
    "            connection_all.append(connection)\n",
    "        else:\n",
    "            special_k.append(k)\n",
    "            connection_all.append([])\n",
    "    subset = -1 * np.ones((0, 20))\n",
    "    candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in special_k:\n",
    "            partAs = connection_all[k][:,0]\n",
    "            partBs = connection_all[k][:,1]\n",
    "            indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "\n",
    "            for i in range(len(connection_all[k])): \n",
    "                found = 0\n",
    "                subset_idx = [-1, -1]\n",
    "                for j in range(len(subset)): \n",
    "                    if subset[j][indexA] == partAs[i] or subset[j][indexB] == partBs[i]:\n",
    "                        subset_idx[found] = j\n",
    "                        found += 1\n",
    "\n",
    "                if found == 1:\n",
    "                    j = subset_idx[0]\n",
    "                    if(subset[j][indexB] != partBs[i]):\n",
    "                        subset[j][indexB] = partBs[i]\n",
    "                        subset[j][-1] += 1\n",
    "                        subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "                elif found == 2: # if found 2 and disjoint, merge them\n",
    "                    j1, j2 = subset_idx\n",
    "                    membership = ((subset[j1]>=0).astype(int) + (subset[j2]>=0).astype(int))[:-2]\n",
    "                    if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
    "                        subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                        subset[j1][-2:] += subset[j2][-2:]\n",
    "                        subset[j1][-2] += connection_all[k][i][2]\n",
    "                        subset = np.delete(subset, j2, 0)\n",
    "                    else: # as like found == 1\n",
    "                        subset[j1][indexB] = partBs[i]\n",
    "                        subset[j1][-1] += 1\n",
    "                        subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(20)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    row[-1] = 2\n",
    "                    row[-2] = sum(candidate[connection_all[k][i,:2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                    subset = np.vstack([subset, row])\n",
    "\n",
    "    # delete some rows of subset which has few parts occur\n",
    "    deleteIdx = [];\n",
    "    for i in range(len(subset)):\n",
    "        if subset[i][-1] < 4 or subset[i][-2]/subset[i][-1] < 0.4:\n",
    "            deleteIdx.append(i)\n",
    "    subset = np.delete(subset, deleteIdx, axis=0)\n",
    "    scale = 8\n",
    "    if len(subset)==2:  #Control to check if OpenPose detected 2 people\n",
    "        df.at[len(df)]=0 #Initialize an Empty Row\n",
    "        df.at[len(df)-1, \"idFrame\"] = numFrame\n",
    "        df.at[len(df)-1, \"Violence\"] = 1 #1 = Non violence, MAKE SURE TO CHANGE TO 0 IF YOU ARE CALCULATING\n",
    "                                                          # VIOLENCE FOLDER BODYPARTS\n",
    "        for i in range(len(subset)):\n",
    "            for j in range(len(subset[i])-2):\n",
    "                cella = subset[i][j]\n",
    "                nomeParte = bodyparts[j] + str(i+1) #Building the string name\n",
    "                if cella != -1:\n",
    "                    X = candidate[cella.astype(int), 0] * scale\n",
    "                    Y = candidate[cella.astype(int), 1] * scale\n",
    "                    df.at[len(df)-1,\"X\"+nomeParte] = X\n",
    "                    df.at[len(df)-1,\"Y\"+nomeParte] = Y #Saving Values in the row\n",
    "    calculateDistances(df) #Calculating the distance for the single frame\n",
    "    numFrame= numFrame+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
